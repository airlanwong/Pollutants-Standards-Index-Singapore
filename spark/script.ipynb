{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Load all the required library and also Start Spark Session\n",
    "# Load all the required library\n",
    "import requests\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "URL = 'https://api.data.gov.sg/v1/environment/pm25'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"wasup\").getOrCreate()\n",
    "sqlContext = SparkSession(spark)\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_body_reponse(response):\n",
    "    if response['api_info']['status'] == 'healthy':\n",
    "        return response\n",
    "    \n",
    "def parameters():\n",
    "    date_time = datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "    return {'date_time':date_time}\n",
    "\n",
    "def request(url,parameters):\n",
    "    r = requests.get(url,params=parameters)\n",
    "    if r.status_code == 200:\n",
    "        print(f'successful API {r.status_code}')\n",
    "        return r\n",
    "    else:\n",
    "        print(f'error API {r.status_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = request(URL,parameters())\n",
    "content = r.json()\n",
    "data = get_body_reponse(content)\n",
    "json_object = json.dumps(data)\n",
    "print(json_object)\n",
    "\n",
    "with open(\"sample.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataframe \n",
    "dataframe = spark.read.format(\"json\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").load(\"sample.json\")\n",
    "dataframe = dataframe.select(col(\"items.readings.pm25_one_hourly.central\").alias(\"pm25_central\"),\n",
    "                            col(\"items.readings.pm25_one_hourly.east\").alias(\"pm25_east\"),\n",
    "                            col(\"items.readings.pm25_one_hourly.north\").alias(\"pm25_north\"),\n",
    "                            col(\"items.readings.pm25_one_hourly.south\").alias(\"pm25_south\"),\n",
    "                            col(\"items.readings.pm25_one_hourly.west\").alias(\"pm25_west\"),\n",
    "                            col(\"items.timestamp\").alias(\"timestamp\"),\n",
    "                            col(\"items.update_timestamp\").alias(\"update_timestamp\"))\n",
    "# show data frame \n",
    "dataframe.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking dataframe schema\n",
    "dataframe.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
